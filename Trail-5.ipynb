{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f911852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D,MaxPooling2D,Dropout,InputLayer,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import cv2\n",
    "import math\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../germany_dataset/train.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df.dropna()\n",
    "filename=\"Trail-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b17bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"length\"] = df[\"Roi.X2\"]-df[\"Roi.X1\"]\n",
    "df[\"height\"] = df[\"Roi.Y2\"]-df[\"Roi.Y1\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929f4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9034e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Variables declaration to use same code for different datasets\n",
    "num_of_classes = df[\"ClassId\"].nunique()\n",
    "resize_x  = 32\n",
    "resize_y  = 32\n",
    "num_of_channels = 3\n",
    "directory = \"../germany_dataset/\"\n",
    "testdir = \"../germany_dataset/test.csv\"\n",
    "Epochs=100\n",
    "train_length = len(df)\n",
    "Y_col_name=\"ClassId\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Functions\n",
    "def remove_outlier(df,parameter):\n",
    "    Percentile25 = df[parameter].quantile(0.25)\n",
    "    Percentile75 = df[parameter].quantile(0.75)\n",
    "    iqr = Percentile75 - Percentile25\n",
    "    lowerlimit = Percentile25 - 1.5*iqr\n",
    "    upperlimit = Percentile75 + 1.5*iqr\n",
    "    temp1 = df[parameter]>lowerlimit\n",
    "    temp2 = df[parameter]<upperlimit\n",
    "    return df[temp1 & temp2] \n",
    "\n",
    "def get_max_index(arr):\n",
    "    length = len(arr)\n",
    "    mini = 0\n",
    "    value = 0\n",
    "    for i,val in enumerate(arr):\n",
    "        if mini < val :\n",
    "            mini = val\n",
    "            value = i\n",
    "    return value\n",
    "\n",
    "def viewStatistics(df):\n",
    "    #Statistics of Data\n",
    "    print(\"Total Training Examples : \",len(df))\n",
    "    values = df[\"ClassId\"].value_counts()\n",
    "    x_labels = [str(x) for x in range(num_of_classes)]\n",
    "    y_labels = []\n",
    "    for x in range(num_of_classes):\n",
    "        y_labels.append(values[x])\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(x_labels,y_labels,width=0.5)\n",
    "    plt.title('Bar Graph')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def Predict_for_single_example(model,img):\n",
    "    img  = np.array(img)\n",
    "    img  = tf.convert_to_tensor(img,dtype=float)\n",
    "    img = img/255.0\n",
    "    img = tf.expand_dims(img, axis=0)\n",
    "    probability = model.predict(img)\n",
    "    value = get_max_index(probability[0])\n",
    "    return value\n",
    "    \n",
    "def Predict_for_Multiple_examples(model,images):\n",
    "    img = []\n",
    "    for j in range(len(images)):\n",
    "        img.append(np.array(images[j]))\n",
    "    img = np.array(img)\n",
    "    img = tf.convert_to_tensor(img,dtype=float)\n",
    "    img = img/255.0\n",
    "    probability = model.predict(img)\n",
    "    values = []\n",
    "    for val in probability:\n",
    "        values.append(get_max_index(val))\n",
    "    return values\n",
    "\n",
    "def PredictTest(model,df,start,length):\n",
    "    images = []\n",
    "    y_test = []\n",
    "    length = min(length,len(df)-start)\n",
    "    for i in range(length):\n",
    "        row = df.loc[start+i].values\n",
    "        images.append(Image.open(directory+row[7]).crop((row[2],row[3],row[4],row[5])).resize((resize_x,resize_y)))\n",
    "        y_test.append(row[6])\n",
    "    \n",
    "\n",
    "    y_predicted = Predict_for_Multiple_examples(model,images)\n",
    "\n",
    "    return y_test,y_predicted\n",
    "\n",
    "def PredictTest(model,df):\n",
    "    images = []\n",
    "    y_test = []\n",
    "    length = len(df)\n",
    "    for i in range(length):\n",
    "        row = df.loc[i].values\n",
    "        images.append(Image.open(directory+row[7]).crop((row[2],row[3],row[4],row[5])).resize((resize_x,resize_y)))\n",
    "        y_test.append(row[6])\n",
    "        \n",
    "    y_predicted = Predict_for_Multiple_examples(model,images)\n",
    "\n",
    "    return y_test,y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870d8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics of Data\n",
    "viewStatistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = len(df)\n",
    "print(\"Total Training Examples : \",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda44fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(Y_col_name, axis=1)\n",
    "y = df[Y_col_name]\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Fit and apply the oversampler to the data\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df[Y_col_name] = y_resampled\n",
    "df[Y_col_name].astype(str)\n",
    "\n",
    "viewStatistics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45563d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a50531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Images and there crop according to data given in csv\n",
    "def showExamples(df):\n",
    "    num_rows = 5\n",
    "    num_cols = 2\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 20))\n",
    "    total_images = []\n",
    "    for i in range(5):\n",
    "        integer = random.randint(0,len(df))\n",
    "        total_images.append(df.iloc[integer].values)\n",
    "    total_images = list(total_images)\n",
    "    for i,val in enumerate(total_images):\n",
    "        row = i\n",
    "        col=0\n",
    "        ax = axes[row, col]\n",
    "        img = Image.open(directory+val[6])\n",
    "        ax.imshow(img)\n",
    "        img = img.crop((val[2],val[3],val[4],val[5]))\n",
    "        ax = axes[row,col+1]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(directory+val[6])\n",
    "        print(directory+val[6])\n",
    "    ax.axis('off')\n",
    "\n",
    "def showTestExamples(df):\n",
    "    num_rows = 5\n",
    "    num_cols = 2\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 20))\n",
    "    total_images = []\n",
    "    for i in range(5):\n",
    "        integer = random.randint(0,len(df))\n",
    "        total_images.append(df.iloc[integer].values)\n",
    "    total_images = list(total_images)\n",
    "    for i,val in enumerate(total_images):\n",
    "        row = i\n",
    "        col=0\n",
    "        ax = axes[row, col]\n",
    "        img = Image.open(directory+val[7])\n",
    "        ax.imshow(img)\n",
    "        img = img.crop((val[2],val[3],val[4],val[5]))\n",
    "        ax = axes[row,col+1]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(\"Class : \"+str(val[6]))\n",
    "    ax.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7069328",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "showExamples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950f020",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load pre-trained  model with random weights\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(resize_x,resize_y,3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_of_classes, activation='softmax') \n",
    "])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053664ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ec5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"ClassId\"].dtype)\n",
    "df[\"ClassId\"] = df[\"ClassId\"].astype(str)\n",
    "print(df[\"ClassId\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self,dataframe, x1_col, y1_col, x2_col, y2_col, Path,directory, preprocessing_function=None, **kwargs):\n",
    "        super().__init__(preprocessing_function=preprocessing_function, **kwargs)\n",
    "        self.dataframe=dataframe\n",
    "        self.directory = directory\n",
    "        self.x1_col = x1_col\n",
    "        self.y1_col = y1_col\n",
    "        self.x2_col = x2_col\n",
    "        self.y2_col = y2_col\n",
    "        self.Path   = Path\n",
    "        \n",
    "\n",
    "    def flow_from_dataframe(self, *args, **kwargs):\n",
    "        generator = super().flow_from_dataframe(*args, **kwargs)\n",
    "        generator.Path = self.Path\n",
    "        return generator\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Override the __getitem__ method to load and preprocess images based on coordinates\n",
    "        current_batch = super().__getitem__(index)\n",
    "        \n",
    "        # Load original images and preprocess based on coordinates\n",
    "        for i in range(len(current_batch[0])):\n",
    "            x1 = self.dataframe[self.x1_col].iloc[index * self.batch_size + i]\n",
    "            y1 = self.dataframe[self.y1_col].iloc[index * self.batch_size + i]\n",
    "            x2 = self.dataframe[self.x2_col].iloc[index * self.batch_size + i]\n",
    "            y2 = self.dataframe[self.y2_col].iloc[index * self.batch_size + i]\n",
    "            original_image_path = self.dataframe[self.Path].iloc[index * self.batch_size + i]\n",
    "            original_image = Image.open(directory+original_image_path)\n",
    "            region = original_image.crop((x1, y1, x2, y2))\n",
    "            region_array = np.array(region)\n",
    "            \n",
    "            # Apply preprocessing_function if specified\n",
    "            if self.preprocessing_function:\n",
    "                region_array = self.preprocessing_function(region_array)\n",
    "\n",
    "            current_batch[0][i] = region_array\n",
    "\n",
    "        return current_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240af09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3352d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3686a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen  = CustomImageDataGenerator(\n",
    "    df,\n",
    "    \"Roi.X1\",\n",
    "    \"Roi.Y1\",\n",
    "    \"Roi.X2\",\n",
    "    \"Roi.Y2\",\n",
    "    \"Path\",\n",
    "    directory,\n",
    "    rescale=1./255,  \n",
    "    rotation_range=20,  \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,  \n",
    "    zoom_range=0.2,  \n",
    "    horizontal_flip=True,  \n",
    "    fill_mode='nearest'  ,\n",
    "    validation_split = 0.2,\n",
    "    samplewise_center=True\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "     df,\n",
    "    x_col='Path',\n",
    "    y_col=\"ClassId\",\n",
    "    target_size=(resize_x,resize_y),\n",
    "    batch_size=32,\n",
    "     directory=directory,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "  df,\n",
    "    x_col='Path',\n",
    "    y_col=\"ClassId\",\n",
    "    target_size=(resize_x,resize_y),\n",
    "    batch_size=32,\n",
    "     directory=directory,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef021053",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "starting_time = time.time()\n",
    "\n",
    "history = model.fit( train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=Epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "ending_time = time.time()\n",
    "total_time = ending_time - starting_time\n",
    "total_time/=60\n",
    "\n",
    "print(\"Time taken fit : \",total_time,\" min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "# model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae5236",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffa10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs  = [x for x in range(Epochs)]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(epochs,training_accuracy,color=\"blue\",label=\"Training Accuracy\")\n",
    "plt.plot(epochs,validation_accuracy,color=\"red\",label=\"Validation Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs  = [x for x in range(Epochs)]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(epochs,loss,color=\"blue\",label=\"training loss\")\n",
    "plt.plot(epochs,val_loss,color=\"red\",label=\"validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710fcbe",
   "metadata": {},
   "source": [
    " ***Test Image Classification and Accuracy Calculation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading weights into CNN model \n",
    "# model = tf.keras.models.load_model(\"CNN_SimpleLayered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5193aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(testdir)\n",
    "df_test[\"ClassId\"] =df_test[\"ClassId\"].astype(str)\n",
    "print(\"Number of Test Images are \", len(df_test))\n",
    "df_test.dropna()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewStatistics(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "showTestExamples(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test.drop(Y_col_name, axis=1)\n",
    "y = df_test[Y_col_name]\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Fit and apply the oversampler to the data\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X, y)\n",
    "\n",
    "df_test = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_test[Y_col_name] = y_resampled\n",
    "df_test[Y_col_name] = df_test[Y_col_name].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dcfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = CustomImageDataGenerator(df_test,\"Roi.X1\",\n",
    "                                   \"Roi.Y1\",\n",
    "                                   \"Roi.X2\",\n",
    "                                   \"Roi.Y2\",\n",
    "                                   \"Path\",\n",
    "                                   directory,\n",
    "                                   rescale=1./255)  # You can add other preprocessing options as needed\n",
    "\n",
    "batch_size = 32  # Adjust based on your requirements\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    x_col='Path',\n",
    "    y_col='ClassId',\n",
    "    directory=directory,\n",
    "    target_size=(resize_x, resize_y),  # Adjust based on your model's input size\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  # Adjust based on your task\n",
    "    shuffle=False  # Set to False for testing to maintain the order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_generator.classes\n",
    "pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691433cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.sum(np.diag(confusion)) / np.sum(confusion)\n",
    "print(\"Total Accuracy: \", accuracy*100)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "classification_rep = classification_report(y_test, y_pred, labels=np.unique(y_pred))\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion)\n",
    "\n",
    "\n",
    "lines = classification_rep.split('\\n')\n",
    "data = []\n",
    "\n",
    "for line in lines[2:-5]:  # Exclude header and footer lines\n",
    "    row_data = line.split()\n",
    "    if len(row_data) > 0:\n",
    "        class_name = row_data[0]\n",
    "        precision = float(row_data[1])\n",
    "        recall = float(row_data[2])\n",
    "        f1_score = float(row_data[3])\n",
    "        support = int(row_data[4])\n",
    "        data.append([class_name, precision, recall, f1_score, support])\n",
    "\n",
    "# Create a DataFrame\n",
    "report = pd.DataFrame(data, columns=['Class', 'Precision', 'Recall', 'F1-Score', 'Support'])\n",
    "# Print the DataFrame\n",
    "print(\"\\n\\n\\n Summarizing the results : \")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ce348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = []\n",
    "for i in range(num_of_classes):\n",
    "    class_names.append(\"Class \"+str(i))\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion, annot=False, cmap=\"viridis\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3e945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
